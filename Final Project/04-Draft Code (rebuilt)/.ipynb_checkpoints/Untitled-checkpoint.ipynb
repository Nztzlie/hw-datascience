{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import spacy\n",
    "import numpy as np\n",
    "from spacy.en import English\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twee = pd.read_csv('Tweets.csv')\n",
    "list(twee.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twee.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twee = twee.drop(['airline_sentiment_gold','negativereason_gold','tweet_coord','tweet_location'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twee.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_sentiment = twee['airline_sentiment'].value_counts()\n",
    "number_of_tweets = twee['tweet_id'].count()\n",
    "print(count_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Index = [1,2,3]\n",
    "plt.bar(Index,count_sentiment)\n",
    "plt.xticks(Index,['negative','neutral','positive'])\n",
    "plt.ylabel('Sentiment Count')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.title('Airline Tweet Sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_zones = twee.groupby(['user_timezone','airline_sentiment']).count().sort_index()\n",
    "mean_zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def by_timezone(timezone):\n",
    "    blob = twee[twee['user_timezone']==timezone]\n",
    "    count_sentiments = blob['airline_sentiment'].value_counts()\n",
    "    Index = [1,2,3]\n",
    "    plt.bar(Index,count_sentiments)\n",
    "    plt.xticks(Index,['negative','neutral','positive'])\n",
    "    plt.title(timezone + ' Sentiment')\n",
    "plt.figure(1,figsize=(12, 12))\n",
    "plt.subplot(231)\n",
    "by_timezone('Eastern Time (US & Canada)')\n",
    "plt.subplot(232)\n",
    "by_timezone('Central Time (US & Canada)')\n",
    "plt.subplot(233)\n",
    "by_timezone('Pacific Time (US & Canada)')\n",
    "plt.subplot(233)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def by_airline(airline):\n",
    "    blob = twee[twee['airline']==airline]\n",
    "    count_sentiments = blob['airline_sentiment'].value_counts()\n",
    "    Index = [1,2,3]\n",
    "    plt.bar(Index,count_sentiments)\n",
    "    plt.xticks(Index,['negative','neutral','positive'])\n",
    "    plt.title(airline + ' Tweet Sentiment')\n",
    "plt.figure(1,figsize=(12, 12))\n",
    "plt.subplot(231)\n",
    "by_airline('US Airways')\n",
    "plt.subplot(232)\n",
    "by_airline('United')\n",
    "plt.subplot(233)\n",
    "by_airline('American')\n",
    "plt.subplot(234)\n",
    "by_airline('Southwest')\n",
    "plt.subplot(235)\n",
    "by_airline('Delta')\n",
    "plt.subplot(236)\n",
    "by_airline('Virgin America')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "airlines_tweet = twee.groupby(['airline']).airline_sentiment.value_counts()\n",
    "airlines_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twee.negativereason.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Series(twee['negativereason']).value_counts().plot(kind = 'bar',title = 'Negative Sentiment Reasons')\n",
    "plt.xlabel('Reason')\n",
    "plt.ylabel('Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtab_percent = pd.crosstab(twee['airline'], twee['airline_sentiment']).apply(lambda r: r/r.sum(), axis=1)\n",
    "xtab_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en')\n",
    "nlp_toolkit = English()\n",
    "nlp_toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_words(originaltweet):\n",
    "    letter = re.sub(\"[^a-zA-Z]\", \"\", originaltweet)\n",
    "    words = [w for w in words if not w in stops] \n",
    "    return(words)\n",
    "    print(words)\n",
    "\n",
    "def the_words(words):\n",
    "    extract_words\n",
    "    return( \"\".join(words)) \n",
    "\n",
    "def tweet_length(words):\n",
    "    extract_words\n",
    "    return(len(words))\n",
    "\n",
    "twee['scrubbed_tweet']=twee['text'].apply(lambda x: the_words(x))\n",
    "twee['length']=twee['text'].apply(lambda x: tweet_length(x))\n",
    "train,test = train_test_split(twee,test_size=0.33,random_state=42)\n",
    "\n",
    "twee['sentiment']=twee['airline_sentiment'].apply(lambda x: 0 if x=='negative' else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_scrubbed_tweet=[]\n",
    "for tweet in train['scrubbed_tweet']:\n",
    "    train_scrubbed_tweet.append(tweet)\n",
    "test_scrubbed_tweet=[]\n",
    "for tweet in test['scrubbed_tweet']:\n",
    "    test_scrubbed_tweet.append(tweet)\n",
    "        \n",
    "print(test_scrubbed_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "v = CountVectorizer(analyzer = \"word\")\n",
    "train_features= v.fit_transform(train_scrubbed_tweet)\n",
    "test_features=v.transform(test_scrubbed_tweet)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
